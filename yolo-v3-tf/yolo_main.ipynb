{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo V3 with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from net.yolo_top import yolov3\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from data.data_pipeline import data_pipeline\n",
    "from net.config import cfg\n",
    "% load_ext autoreload\n",
    "% autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_data(database_path):\n",
    "    # from tfrecord format database read imgs and boxes\n",
    "    imgs, true_boxes = data_pipeline(database_path, cfg.batch_size)\n",
    "    return imgs, true_boxes\n",
    "    \n",
    "def build_model(imgs, true_boxes):\n",
    "    # set model status\n",
    "    istraining = tf.constant(True, tf.bool)\n",
    "    # build whole yolov3 model\n",
    "    model = yolov3(imgs, true_boxes, istraining)\n",
    "    \n",
    "    # get loss\n",
    "    loss = model.compute_loss()\n",
    "    \n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    # lr = tf.train.exponential_decay(0.0001, global_step=global_step, decay_steps=2e4, decay_rate=0.1)\n",
    "    lr = tf.train.piecewise_constant(global_step, [40000, 45000], [1e-3, 1e-4, 1e-5])\n",
    "    \n",
    "    # get optimizer\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr)\n",
    "    # optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)\n",
    "    update_op = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    vars_det = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Head\")\n",
    "    # for var in vars_det:\n",
    "    #     print(var)\n",
    "    with tf.control_dependencies(update_op):\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step, var_list=vars_det)\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    return model, train_op, loss, saver, global_step\n",
    "\n",
    "def train_model(train_op, loss, saver, global_step):   \n",
    "    gs = 0\n",
    "    batch_per_epoch = 2000\n",
    "    cfg.train.max_batches = int(batch_per_epoch * 10)\n",
    "    cfg.train.image_resized = 608\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        ckpt = tf.train.get_checkpoint_state(cfg.path.ckpt_dir)\n",
    "        if (ckpt and ckpt.model_checkpoint_path):\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            gs = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "            sess.run(tf.assign(global_step, gs))\n",
    "            print('Restore batch: ', gs)\n",
    "        else:\n",
    "            print('no checkpoint found')\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "        for i in range(gs, cfg.train.max_batches):\n",
    "            _, loss_ = sess.run([train_op, loss])\n",
    "            if(i % 100 == 0):\n",
    "                print(i,': ', loss_)\n",
    "            if(i % 1000 == 0):\n",
    "                saver.save(sess, cfg.path.ckpt_dir+'yolov3.ckpt', global_step=global_step, write_meta_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darknet\n",
      "(?, 608, 608, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsimage-x/anaconda3/envs/tensorflow-work/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:100: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "imgs, true_boxes = build_data(cfg.path.train_data_path)\n",
    "model, train_op, loss, saver, global_step = build_model(imgs, true_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 608, 608, 3)\n",
      "(?, 608, 608, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imgs.shape)\n",
    "print(model.img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/yolov3.ckpt-1\n",
      "Restore batch:  1\n",
      "100 :  185.073\n",
      "200 :  321.729\n",
      "300 :  75.4954\n",
      "400 :  113.673\n",
      "500 :  75.3663\n",
      "600 :  85.4102\n",
      "700 :  54.4702\n",
      "800 :  90.2194\n",
      "900 :  43.5213\n",
      "1000 :  43.3888\n",
      "1100 :  78.0176\n",
      "1200 :  46.2254\n",
      "1300 :  56.5917\n",
      "1400 :  106.116\n",
      "1500 :  63.1553\n",
      "1600 :  49.5945\n",
      "1700 :  59.0254\n",
      "1800 :  43.4884\n",
      "1900 :  47.833\n",
      "2000 :  57.9187\n",
      "2100 :  111.791\n",
      "2200 :  65.7887\n",
      "2300 :  45.7487\n",
      "2400 :  43.7859\n",
      "2500 :  37.265\n",
      "2600 :  39.9885\n",
      "2700 :  51.0216\n",
      "2800 :  44.2853\n",
      "2900 :  32.4721\n",
      "3000 :  33.8502\n",
      "3100 :  31.3938\n",
      "3200 :  38.6412\n",
      "3300 :  37.0735\n",
      "3400 :  45.5054\n",
      "3500 :  32.663\n",
      "3600 :  51.0515\n",
      "3700 :  60.4868\n",
      "3800 :  66.2721\n",
      "3900 :  24.2105\n",
      "4000 :  44.0316\n",
      "4100 :  34.9523\n",
      "4200 :  34.3413\n",
      "4300 :  40.8378\n",
      "4400 :  31.5358\n",
      "4500 :  69.7347\n",
      "4600 :  49.0802\n",
      "4700 :  29.9731\n",
      "4800 :  31.1307\n",
      "4900 :  31.727\n",
      "5000 :  61.2346\n",
      "5100 :  27.8853\n",
      "5200 :  24.304\n",
      "5300 :  19.6182\n",
      "5400 :  33.8224\n",
      "5500 :  36.1826\n",
      "5600 :  22.9399\n",
      "5700 :  35.7016\n",
      "5800 :  28.2625\n",
      "5900 :  32.0104\n",
      "6000 :  54.2884\n",
      "6100 :  25.2572\n",
      "6200 :  36.992\n",
      "6300 :  29.903\n",
      "6400 :  24.1163\n",
      "6500 :  26.4073\n",
      "6600 :  28.538\n",
      "6700 :  17.7322\n",
      "6800 :  15.3309\n",
      "6900 :  16.988\n",
      "7000 :  16.0538\n",
      "7100 :  22.8617\n",
      "7200 :  14.3618\n",
      "7300 :  33.7481\n",
      "7400 :  20.7727\n",
      "7500 :  66.7076\n",
      "7600 :  39.2241\n",
      "7700 :  55.9135\n",
      "7800 :  72.0235\n",
      "7900 :  34.7719\n",
      "8000 :  27.5173\n",
      "8100 :  20.6601\n",
      "8200 :  27.2357\n",
      "8300 :  28.7446\n",
      "8400 :  25.8117\n",
      "8500 :  29.4876\n",
      "8600 :  18.4669\n",
      "8700 :  11.4201\n"
     ]
    }
   ],
   "source": [
    "train_model(train_op, loss, saver, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
